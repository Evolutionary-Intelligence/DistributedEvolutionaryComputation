
* [Miikkulainen, R.](https://www.cs.utexas.edu/users/risto/) and [Forrest, S.](https://www.cs.unm.edu/~forrest/), 2021. [A biological perspective on evolutionary computation](https://www.nature.com/articles/s42256-020-00278-8). Nature Machine Intelligence, 3(1), pp.9-15.
* [Eiben, A.E.](https://www.cs.vu.nl/~gusz/) and [Smith, J.](http://www.cems.uwe.ac.uk/~jsmith/), 2015. [From evolutionary computation to the evolution of things](https://www.nature.com/articles/nature14544). Nature, 521(7553), pp.476-482. [ http://www.evolutionarycomputation.org/ ]
* Bonabeau, E., [Dorigo, M.](https://iridia.ulb.ac.be/~mdorigo/HomePageDorigo/index.php) and Theraulaz, G., 2000. [Inspiration for optimization from social insect behaviour](https://www.nature.com/articles/35017500). Nature, 406(6791), pp.39-42.
* [Forrest, S.](https://www.cs.unm.edu/~forrest/), 1993. [Genetic algorithms: Principles of natural selection applied to computation](https://www.science.org/doi/10.1126/science.8346439). Science, 261(5123), pp.872-878.
* Bounds, D.G., 1987. [New optimization methods from physics and biology](https://www.nature.com/articles/329215a0). Nature, 329(6136), pp.215-219.
* [Back, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back), Hammel, U. and [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1997. [Evolutionary computation: Comments on the history and current state](https://ieeexplore.ieee.org/document/585888). IEEE Transactions on Evolutionary Computation, 1(1), pp.3-17.
  * [Back, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back), 1996. [Evolutionary algorithms in theory and practice: Evolution strategies, evolutionary programming, genetic algorithms](https://academic.oup.com/book/40791). Oxford University Press.
  * [Bäck, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back) and [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1993. [An overview of evolutionary algorithms for parameter optimization](https://direct.mit.edu/evco/article-abstract/1/1/1/1092/An-Overview-of-Evolutionary-Algorithms-for). Evolutionary Computation, 1(1), pp.1-23.
* Wolpert, D.H. and Macready, W.G., 1997. No free lunch theorems for optimization. IEEE Transactions on Evolutionary Computation, 1(1), pp.67-82.

## Genetic Algorithm (GA)

* [Whitley, D.](https://www.cs.colostate.edu/~whitley/), 2019. [Next generation genetic algorithms: A user’s guide and tutorial](https://link.springer.com/chapter/10.1007/978-3-319-91086-4_8). In Handbook of Metaheuristics (pp. 245-274). Springer, Cham.
  * [Whitley, D.](https://www.cs.colostate.edu/~whitley/), Rana, S., Dzubera, J. and Mathias, K.E., 1996. [Evaluating evolutionary algorithms](https://www.sciencedirect.com/science/article/pii/0004370295001247). Artificial Intelligence, 85(1-2), pp.245-276.
  * [Whitley, D.](https://www.cs.colostate.edu/~whitley/), 1994. [A genetic algorithm tutorial](https://link.springer.com/article/10.1007/BF00175354). Statistics and Computing, 4(2), pp.65-85.
  * [Whitley, D.](https://www.cs.colostate.edu/~whitley/), Dominic, S., Das, R. and Anderson, C.W., 1993. [Genetic reinforcement learning for neurocontrol problems](https://link.springer.com/article/10.1023/A:1022674030396). Machine Learning, 13, pp.259-284.
* Mitchell, M., 1998. [An introduction to genetic algorithms](https://direct.mit.edu/books/book/4675/An-Introduction-to-Genetic-Algorithms). MIT Press.
  * Mitchell, M. and Taylor, C.E., 1999. [Evolutionary computation: An overview](https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.30.1.593). Annual Review of Ecology and Systematics, 30(1), pp.593-616.
  * Mitchell, M., Holland, J. and Forrest, S., 1993. [When will a genetic algorithm outperform hill climbing](https://proceedings.neurips.cc/paper/1993/hash/ab88b15733f543179858600245108dd8-Abstract.html). Advances in Neural Information Processing Systems (pp. 51-58).
* [Forrest, S.](https://www.cs.unm.edu/~forrest/), 1993. [Genetic algorithms: Principles of natural selection applied to computation](https://www.science.org/doi/10.1126/science.8346439). Science, 261(5123), pp.872-878.
  * [Forrest, S.](https://www.cs.unm.edu/~forrest/), 1996. [Genetic algorithms](https://dl.acm.org/doi/pdf/10.1145/234313.234350). ACM Computing Surveys, 28(1), pp.77-80.
  * Jones, T. and Forrest, S., 1995, July. [Fitness distance correlation as a measure of problem difficulty for genetic algorithms](http://sfi-edu.s3.amazonaws.com/sfi-edu/production/uploads/sfi-com/dev/uploads/filer/bf/eb/bfeb9cb0-100f-44d9-a35f-e95243dba350/95-02-022.pdf). In Proceedings of International Conference on Genetic Algorithms (pp. 184-192).
* Goldberg, D.E., 1989. [Genetic algorithms in search, optimization and machine learning](https://www.goodreads.com/en/book/show/142613). Reading: Addison-Wesley.
  * Goldberg, D.E. and Holland, J.H., 1988. [Genetic algorithms and machine learning](https://link.springer.com/article/10.1023/A:1022602019183). Machine Learning, 3(2), pp.95-99.
  * Goldberg, D.E., 1994. [Genetic and evolutionary algorithms come of age](https://dl.acm.org/doi/10.1145/175247.175259). Communications of the ACM, 37(3), pp.113-120.
* De Jong, K.A., 1975. [An analysis of the behavior of a class of genetic adaptive systems](https://deepblue.lib.umich.edu/bitstream/handle/2027.42/4507/bab6360.0001.001.pdf). Doctoral Dissertation, University of Michigan.
  * De Jong, K.A., 2006. [Evolutionary computation: A unified approach](https://ieeexplore.ieee.org/book/6267245). MIT Press.
  * De Jong, K.A., 1992. [Are genetic algorithms function optimizer?](https://www.mli.gmu.edu/papers/91-95/92-20.pdf). International Conference on Parallel Problem Solving from Nature, pp.3-13.
  * De Jong, K.A., 1988. [Learning with genetic algorithms: An overview](https://link.springer.com/article/10.1007/BF00113894). Machine Learning, 3, pp.121-138.
* Holland, J.H., 1962. [Outline for a logical theory of adaptive systems](https://dl.acm.org/doi/10.1145/321127.321128). Journal of the ACM, 9(3), pp.297-314. [ [UMICH Ph.D.](https://www.proquest.com/openview/9c228542954e5bb676739359ff6341ef/1?pq-origsite=gscholar&cbl=18750&diss=y) ]
  * Forrest, S. and Mitchell, M., 2016. [Adaptive computation: The multidisciplinary legacy of John H. Holland](https://cacm.acm.org/magazines/2016/8/205047-adaptive-computation/abstract). Communications of the ACM, 59(8), pp.58-63.
  * Husbands, P., 2008. [An interview with John Holland](https://users.sussex.ac.uk/~philh/pubs/HollandINTV.pdf). Mechanical Mind in History, p.389.
  * Holland, J.H., 1992. [Genetic algorithms](https://www.scientificamerican.com/article/genetic-algorithms/). Scientific American, 267(1), pp.66-73.
  * Holland, J.H., 1992. [Adaptation in natural and artificial systems: An introductory analysis with applications to biology, control, and artificial intelligence](https://direct.mit.edu/books/book/2574/Adaptation-in-Natural-and-Artificial-SystemsAn). MIT Press.
  * Holland, J.H., 1975. [Adaptation in natural and artificial systems: An introductory analysis with applications to biology, control, and artificial intelligence](https://direct.mit.edu/books/book/2574/Adaptation-in-Natural-and-Artificial-SystemsAn). University of Michigan Press.
  * Holland, J.H., 1973. [Genetic algorithms and the optimal allocation of trials](https://epubs.siam.org/doi/10.1137/0202009). SIAM Journal on Computing, 2(2), pp.88-105.

## Evolution Strategies (ES)

* Vicol, P., Metz, L. and Sohl-Dickstein, J., 2021, July. [Unbiased gradient estimation in unrolled computation graphs with persistent evolution strategies](http://proceedings.mlr.press/v139/vicol21a.html). In International Conference on Machine Learning (pp. 10553-10563). PMLR. [ [Outstanding Paper](https://icml.cc/virtual/2021/oral/10176) ]
* Nesterov, Y. and Spokoiny, V., 2017. [Random gradient-free minimization of convex functions](https://link.springer.com/article/10.1007/s10208-015-9296-2). Foundations of Computational Mathematics, 17(2), pp.527-566.
  * Choromanski, K., Rowland, M., Sindhwani, V., Turner, R. and Weller, A., 2018, July. [Structured evolution with compact architectures for scalable policy optimization](http://proceedings.mlr.press/v80/choromanski18a.html). In International Conference on Machine Learning (pp. 970-978). PMLR.
  * Diouane, Y., Gratton, S. and Vicente, L.N., 2015. [Globally convergent evolution strategies](https://link.springer.com/article/10.1007/s10107-014-0793-x). Mathematical Programming, 152, pp.467-490.
* [Bringmann, K.](https://people.mpi-inf.mpg.de/~kbringma/), Friedrich, T., [Igel, C.](https://christian-igel.github.io/) and Voß, T., 2013. [Speeding up many-objective optimization by Monte Carlo approximations](https://www.sciencedirect.com/science/article/pii/S0004370213000738). Artificial Intelligence, 204, pp.22-29.
  * [Igel, C.](https://christian-igel.github.io/), [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/) and Roth, S., 2007. [Covariance matrix adaptation for multi-objective optimization](https://direct.mit.edu/evco/article-abstract/15/1/1/1257/Covariance-Matrix-Adaptation-for-Multi-objective). Evolutionary Computation, 15(1), pp.1-28.
* Ollivier, Y., Arnold, L., Auger, A. and [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/), 2017. [Information-geometric optimization algorithms: A unifying picture via invariance principles](https://www.jmlr.org/papers/v18/14-467.html). Journal of Machine Learning Research, 18(18), pp.1-65. [ [invariance](https://link.springer.com/chapter/10.1007/3-540-45356-3_35) ]
  * [Akimoto, Y.](https://sites.google.com/site/youheiakimotospage/) and [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/), 2020. [Diagonal acceleration for covariance matrix adaptation evolution strategies](https://direct.mit.edu/evco/article/28/3/405/94999/Diagonal-Acceleration-for-Covariance-Matrix). Evolutionary Computation, 28(3), pp.405-435. [ [Akimoto et al., 2010, PPSN](https://link.springer.com/chapter/10.1007/978-3-642-15844-5_16) + [Akimoto et al., 2012, Algorithmica](https://link.springer.com/article/10.1007/s00453-011-9564-8) ]
  * [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/), Arnold, D.V. and Auger, A., 2015. [Evolution strategies](https://link.springer.com/chapter/10.1007/978-3-662-43505-2_44). In Springer Handbook of Computational Intelligence (pp. 871-898). Springer, Berlin, Heidelberg.
  * [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/) and Auger, A., 2014. [Principled design of continuous stochastic search: From theory to practice](https://link.springer.com/chapter/10.1007/978-3-642-33206-7_8). Theory and Principled Methods for the Design of Metaheuristics, pp.145-180.
  * [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/), Müller, S.D. and Koumoutsakos, P., 2003. [Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)](https://direct.mit.edu/evco/article-abstract/11/1/1/1139/Reducing-the-Time-Complexity-of-the-Derandomized). Evolutionary Computation, 11(1), pp.1-18.
  * [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/) and Ostermeier, A., 2001. [Completely derandomized self-adaptation in evolution strategies](https://direct.mit.edu/evco/article-abstract/9/2/159/892/Completely-Derandomized-Self-Adaptation-in). Evolutionary Computation, 9(2), pp.159-195.
  * [Hansen, N.](http://www.cmap.polytechnique.fr/~nikolaus.hansen/) and Ostermeier, A., 1996, May. [Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation](https://ieeexplore.ieee.org/abstract/document/542381). In Proceedings of IEEE International Conference on Evolutionary Computation (pp. 312-317). IEEE. [ [Hansen&Ostermeier, 1997, EUFIT](http://www.cmap.polytechnique.fr/~nikolaus.hansen/CMAES2.ps.gz) | [A Comparing Review](https://link.springer.com/chapter/10.1007/3-540-32494-1_4) | [A Comparative Review](https://link.springer.com/article/10.1023/B:NACO.0000023416.59689.4e) ]
* [Bäck, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back), Foussette, C. and Krause, P., 2013. [Contemporary evolution strategies](https://link.springer.com/book/10.1007/978-3-642-40137-4). Berlin: Springer. [ [mirrored orthogonal sampling](https://direct.mit.edu/evco/article-abstract/27/4/699/94971/Mirrored-Orthogonal-Sampling-for-Covariance-Matrix) ] [ Thomas Bäck: [IEEE Evolutionary Computation Pioneer Award](https://cis.ieee.org/awards/past-recipients) + [IEEE Fellow](https://www.universiteitleiden.nl/en/news/2021/11/thomas-back-appointed-to-ieee-fellow) ]
  * [Shir, O.M.](https://ofersh.github.io/telhai/), Emmerich, M. and [Bäck, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back), 2010. [Adaptive niche radii and niche shapes approaches for niching with the CMA-ES](https://direct.mit.edu/evco/article-abstract/18/1/97/1335/Adaptive-Niche-Radii-and-Niche-Shapes-Approaches). Evolutionary Computation, 18(1), pp.97-126.
  * [Bäck, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back) and Hoffmeister, F., 1994. [Basic aspects of evolution strategies](https://link.springer.com/article/10.1007/BF00175353). Statistics and Computing, 4, pp.51-63.
  * [Bäck, T.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back), Hoffmeister, F. and [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1991. [A survey of evolution strategies](https://www.universiteitleiden.nl/en/staffmembers/thomas-back). In Proceedings of International Conference on Genetic Algorithms.
* [Beyer, H.G.](https://homepages.fhv.at/hgb/) and Schwefel, H.P., 2002. [Evolution strategies–A comprehensive introduction](https://link.springer.com/article/10.1023/A:1015059928466). Natural Computing, 1(1), pp.3-52. [ [MA-ES](https://ieeexplore.ieee.org/abstract/document/7875115) | [Sendhoff et al., 1997, ICGA: Strong Causality](https://arxiv.org/pdf/adap-org/9711001.pdf) ]
  * [Loshchilov, I.](http://www.loshchilov.com/), [Glasmachers, T.](https://www.ini.rub.de/the_institute/people/tobias-glasmachers/) and [Beyer, H.G.](https://homepages.fhv.at/hgb/), 2018. [Large scale black-box optimization by limited-memory matrix adaptation](https://ieeexplore.ieee.org/abstract/document/8410043). IEEE Transactions on Evolutionary Computation, 23(2), pp.353-358.
    * [Loshchilov, I.](http://www.loshchilov.com/), 2017. [LM-CMA: An alternative to L-BFGS for large-scale black box optimization](https://direct.mit.edu/evco/article-abstract/25/1/143/1041/LM-CMA-An-Alternative-to-L-BFGS-for-Large-Scale). Evolutionary Computation, 25(1), pp.143-171.
  * [Arnold, D.V.](https://web.cs.dal.ca/~dirk/) and Beyer, H.G., 2004. [Performance analysis of evolutionary optimization with cumulative step length adaptation](https://ieeexplore.ieee.org/abstract/document/1284729). IEEE Transactions on Automatic Control, 49(4), pp.617-622.
  * Beyer, H.G., 2001. [The theory of evolution strategies](https://link.springer.com/book/10.1007/978-3-662-04378-3). Springer Science & Business Media.
  * Beyer, H.G., 1995. [Toward a theory of evolution strategies: On the benefits of sex—The (μ/μ, λ) theory](https://direct.mit.edu/evco/article-abstract/3/1/81/738/Toward-a-Theory-of-Evolution-Strategies-On-the). Evolutionary Computation, 3(1), pp.81-111.
  * Beyer, H.G., 1994. [Toward a theory of evolution strategies: The (μ, λ)-theory](https://direct.mit.edu/evco/article-abstract/2/4/381/1402/Toward-a-Theory-of-Evolution-Strategies-The-Theory). Evolutionary Computation, 2(4), pp.381-407.
* [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1984. [Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution](https://link.springer.com/article/10.1007/BF01876146). Annals of Operations Research, 1(2), pp.165-167. [ [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/): [IEEE Frank Rosenblatt Award](https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/awards/recipients/rosenblatt-rl.pdf) + IEEE Evolutionary Computation Pioneer Award + IEEE Fellow | [1998, WCCI](https://ieeexplore.ieee.org/abstract/document/699061) ]
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 2002. [Deep insight from simple models of evolution](https://www.sciencedirect.com/science/article/abs/pii/S0303264701001861). BioSystems, 64(1-3), pp.189-198.
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1994. On the evolution of evolutionary computation. Computational Intelligence: Imitating Life, pp.116-124.
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1993. [Evolution and optimum seeking: The sixth generation](https://www.amazon.co.uk/Evolution-Optimum-Generation-Computer-Technologies/dp/0471571482). John Wiley & Sons, Inc..
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1992. [Natural evolution and collective optimum seeking](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7221f5be8ca17ee9cd8fe638cf2ad4886bd66262). Computational Systems Analysis–Topics and Trends, pp.5-14.
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1988. [Evolutionary learning optimum-seeking on parallel computer architectures](https://link.springer.com/chapter/10.1007/978-1-4684-6389-7_46). In Systems Analysis and Simulation I (pp. 217-225). Springer, New York, NY.
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1988. [Collective intelligence in evolving systems](https://link.springer.com/chapter/10.1007/978-3-642-73953-8_8). In Ecodynamics (pp. 95-100). Springer, Berlin, Heidelberg.
  * [Schwefel, H.P.](https://ls11-www.cs.tu-dortmund.de/people/schwefel/), 1981. [Numerical optimization of computer models](https://www.amazon.com/Numerical-optimization-computer-Hans-Paul-Schwefel/dp/0471099880). John Wiley & Sons, Inc.. [ [SIAM Review](https://epubs.siam.org/doi/abs/10.1137/1025106) | [Journal of the Operational Research Society](https://link.springer.com/article/10.1057/jors.1982.238) ]
  * Schwefel, H.P., 2012. [Ubiquity symposium: Evolutionary computation and the processes of life: life lessons taught by simulated evolution](https://dl.acm.org/doi/10.1145/2369296.2369297). ACM Ubiquity, 2012(September), pp.1-9.
  * Schwefel, H.P. and de Brito Mendes, M.A., 2010. [45 years of evolution strategies: Hans-Paul Schwefel interviewed for the genetic argonaut blog](https://dl.acm.org/doi/abs/10.1145/1810132.1810133). ACM SIGEVOlution, 4(2), pp.2-8.
  * Schwefel, H.P., 2008. [An interview with Hans-Paul Schwefel: With an introduction by Günter Rudolph](https://dl.acm.org/doi/abs/10.1145/1621943.1621944). ACM SIGEVOlution, 3(4), pp.2-5.
* [Rechenberg, I.](https://web.archive.org/web/20180425010001/http://www.bionik.tu-berlin.de/institut/xstart.htm), 1989. [Evolution strategy: Nature’s way of optimization](https://link.springer.com/chapter/10.1007/978-3-642-83814-9_6). In Optimization: Methods and Applications, Possibilities and Limitations (pp. 106-126). Springer, Berlin, Heidelberg. [ [Rechenberg, I.](https://web.archive.org/web/20180425010001/http://www.bionik.tu-berlin.de/institut/xstart.htm): IEEE Evolutionary Computation Pioneer Award ]
  * [Rechenberg, I.](https://web.archive.org/web/20180425010001/http://www.bionik.tu-berlin.de/institut/xstart.htm), 2000. [Case studies in evolutionary experimentation and computation](https://www.sciencedirect.com/science/article/pii/S0045782599003813). Computer Methods in Applied Mechanics and Engineering, 186(2-4), pp.125-140.
  * [Rechenberg, I.](https://web.archive.org/web/20180425010001/http://www.bionik.tu-berlin.de/institut/xstart.htm), 1984. [The evolution strategy. A mathematical model of darwinian evolution](https://link.springer.com/chapter/10.1007/978-3-642-69540-7_13). In Synergetics—from Microscopic to Macroscopic Order (pp. 122-132). Springer, Berlin, Heidelberg.
  * [Rechenberg, I.](https://web.archive.org/web/20180425010001/http://www.bionik.tu-berlin.de/institut/xstart.htm), 1973. Evolutionsstrategie: Optimierung technischer systeme nach prinzipien der biologischen evolution. Frommann-Holzboog Verlag, Stuttgart. [NOTE that this seminal Ph.D. dissertation is not read by us since it was originally written in German. But here we still add it owing to its **pioneering** contributions to EC.]
  * Auger, A., Hansen, N., López-Ibáñez, M. and Rudolph, G., 2022. [Tributes to Ingo Rechenberg (1934--2021)](https://dl.acm.org/doi/10.1145/3511282.3511283). ACM SIGEVOlution, 14(4), pp.1-4.

## Evolutionary Programming (EP)

* **Evolutionary Intelligence 2008**: [Dedication: Dr. Lawrence J. Fogel (1928–2007)](https://link.springer.com/article/10.1007/s12065-007-0006-0) + **ECJ 2007**: [In Memoriam Laurence J. Fogel](https://direct.mit.edu/evco/article-abstract/15/2/iii/1264/In-Memoriam-Laurence-J-Fogel)
* Cui, G., Wong, M.L. and Lui, H.K., 2006. [Machine learning for direct marketing response models: Bayesian networks with evolutionary programming](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1060.0514). Management Science, 52(4), pp.597-612.
* Fogel, D.B., Hays, T.J., Hahn, S.L. and Quon, J., 2004. [A self-learning evolutionary chess program](https://ieeexplore.ieee.org/abstract/document/1360168). Proceedings of the IEEE, 92(12), pp.1947-1954.
  * Chellapilla, K. and Fogel, D.B., 1999. [Evolution, neural networks, games, and intelligence](https://ieeexplore.ieee.org/abstract/document/784222). Proceedings of the IEEE, 87(9), pp.1471-1496.
* Yao, X., Liu, Y. and Lin, G., 1999. [Evolutionary programming made faster](https://ieeexplore.ieee.org/abstract/document/771163). IEEE Transactions on Evolutionary Computation, 3(2), pp.82-102.
* Fogel, D.B., 1994. [Evolutionary programming: An introduction and some current directions](https://link.springer.com/article/10.1007/BF00175356). Statistics and Computing, 4, pp.113-129.
  * [Fogel, D.B.](http://www.davidfogel.com/), 2006. [Evolutionary computation: Toward a new philosophy of machine intelligence](https://ieeexplore.ieee.org/book/5237910). John Wiley & Sons.
  * Fogel, D.B., 1999. [An overview of evolutionary programming](https://link.springer.com/chapter/10.1007/978-1-4612-1542-4_5). In Evolutionary Algorithms (pp. 89-109). Springer, New York, NY.
  * Fogel, D.B., 1998. [Evolutionary computation: The fossil record](https://ieeexplore.ieee.org/book/5263042). IEEE Press.
  * Fogel, D.B., 1998. [Unearthing a fossil from the history of evolutionary computation](https://dl.acm.org/doi/10.5555/2379195.2379196). Fundamenta Informaticae, 35(1-4), pp.1-16.
  * Fogel, D.B. and Fogel, L.J., 1995, September. [An introduction to evolutionary programming](https://link.springer.com/chapter/10.1007/3-540-61108-8_28). In European Conference on Artificial Evolution (pp. 21-33). Springer, Berlin, Heidelberg.
  * Fogel, D.B., 1994. [An introduction to simulated evolutionary optimization](https://ieeexplore.ieee.org/abstract/document/265956). IEEE Transactions on Neural Networks, 5(1), pp.3-14.
* Fogel, D.B., Fogel, L.J. and Atmar, J.W., 1991, January. [Meta-evolutionary programming](https://ieeexplore.ieee.org/document/186507). In Conference Record of Asilomar Conference on Signals, Systems & Computers (pp. 540-541). IEEE Computer Society.
* Fogel, L.J., Owens, A.J. and Walsh, M.J., 1965. [Intelligent decision making through a simulation of evolution](https://ieeexplore.ieee.org/document/6591252). IEEE Transactions on Human Factors in Electronics, 6(1), pp.13-23. [ LAWRENCE J. FOGEL : IEEE Frank Rosenblatt Award + IEEE Evolutionary Computation Pioneer Award + IEEE Life Fellow ]
  * Fogel, L.J., Owens, A.J. and Walsh, M.J., 1965. [Intelligent decision-making through a simulation of evolution](https://journals.sagepub.com/doi/abs/10.1177/003754976500500413?journalCode=simb). Simulation, 5(4), pp.267-279.
  * Fogel, L.J., Owens, A.J. and Walsh, M.J., 1966. [Intelligent decision making through a simulation of evolution](https://onlinelibrary.wiley.com/doi/abs/10.1002/bs.3830110403). Behavioral Science, 11(4), pp.253-272.
  * Fogel, L.J., Owens, A.J. and Walsh, M.J., 1966. [Artificial intelligence through simulated evolution](https://www.amazon.com.au/Artificial-Intelligence-Through-Simulated-Evolution/dp/0471265160). John Wiley & Sons Inc.

## Genetic Programming (GP) [ [PySR](https://arxiv.org/pdf/2305.01582.pdf) | [USC Ph.D.](http://www0.cs.ucl.ac.uk/staff/wlangdon/ftp/public/ftp.io.com/papers/WAT_PHD_DissFull_USC94_Recombination_etc_Genetic_Construction_of_Computer_Programs.pdf) ]

* [http://gpbib.cs.ucl.ac.uk/](http://gpbib.cs.ucl.ac.uk/) + https://geneticprogramming.com/
* Langdon, W.B., 2020. Genetic programming and evolvable machines at 20. Genetic Programming and Evolvable Machines, 21(1), pp.205-217.
* Langdon, W.B. and Poli, R., 2013. Foundations of genetic programming. Springer Science & Business Media.
* Schmidt, M. and Lipson, H., 2009. Distilling free-form natural laws from experimental data. Science, 324(5923), pp.81-85.
* Banzhaf, W., Nordin, P., Keller, R.E. and Francone, F.D., 1998. Genetic programming: An introduction on the automatic evolution of computer programs and its applications. Morgan Kaufmann Publishers Inc..
* Koza, J.R., 1994. Genetic programming as a means for programming computers by natural selection. Statistics and Computing, 4(2), pp.87-112.
  * Koza, J.R., Bennet, F.H., Andre, D. and Keane, M.A., 1999. Genetic programming III: Automatic synthesis of analog circuits. MIT Press.
  * Koza, J.R., 1994. Genetic programming II: Automatic discovery of reusable programs. MIT Press.
  * Koza, J.R., 1992. Genetic programming: On the programming of computers by means of natural selection. MIT Press.
  * Koza, J.R., 1990. Non-linear genetic algorithms for solving problems. U.S. Patent 4,935,877.
  * Koza, J.R., 1989, August. Hierarchical genetic algorithms operating on populations of computer programs. In Proceedings of International Joint Conference on Artificial Intelligence (pp. 768-774).
* Cramer, N.L., 1985, July. [A representation for the adaptive generation of simple sequential programs](https://dl.acm.org/doi/10.5555/645511.657085). In Proceedings of International Conference on Genetic Algorithms (pp. 183-187).
* Forsyth, R., 1981. [BEAGLE—A Darwinian approach to pattern recognition](http://www-dept.cs.ucl.ac.uk/staff/W.Langdon/ftp/public/papers/kybernetes_forsyth.pdf). Kybernetes, 10(3), pp.159-166.

## Ant Colony Optimization (ACO)

* https://iridia.ulb.ac.be/~mdorigo/HomePageDorigo/    (This is the official homepage of ACO's inventor **Marco Dorigo**, which includes much information about ACO.) [ [AAAI Fellow](https://aaai.org/about-aaai/aaai-awards/the-aaai-fellows-program/elected-aaai-fellows/) + [IEEE Frank Rosenblatt Award](https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/awards/recipients/rosenblatt-rl.pdf) + IEEE Fellow + [IEEE Evolutionary Computation Pioneer Award](https://cis.ieee.org/awards/past-recipients) ]
* Dorigo, M. and Stützle, T., 2019. Ant colony optimization: Overview and recent advances. Handbook of Metaheuristics, pp.311-351.
* Dorigo, M., Birattari, M. and Stutzle, T., 2006. Ant colony optimization. IEEE Computational Intelligence Magazine, 1(4), pp.28-39.
* Dorigo, M. and Blum, C., 2005. Ant colony optimization theory: A survey. Theoretical Computer Science, 344(2-3), pp.243-278.
* Stützle, T. and Hoos, H.H., 2000. MAX–MIN ant system. Future Generation Computer Systems, 16(8), pp.889-914.
* Gambardella, L.M. and Dorigo, M., 2000. An ant colony system hybridized with a new local search for the sequential ordering problem. INFORMS Journal on Computing, 12(3), pp.237-255.
* Bonabeau, E., Dorigo, M. and Theraulaz, G., 2000. Inspiration for optimization from social insect behaviour. Nature, 406(6791), pp.39-42.
* Maniezzo, V. and Colorni, A., 1999. The ant system applied to the quadratic assignment problem. IEEE Transactions on Knowledge and Data Engineering, 11(5), pp.769-778.
* Bonabeau, E., Dorigo, M. and Theraulaz, G., 1999. Swarm intelligence: from natural to artificial systems. Oxford University Press.
* Gambardella, L.M., Taillard, É.D. and Dorigo, M., 1999. Ant colonies for the quadratic assignment problem. Journal of the Operational Research Society, 50(2), pp.167-176.
* Dorigo, M., Di Caro, G. and Gambardella, L.M., 1999. [Ant algorithms for discrete optimization](https://direct.mit.edu/artl/article-abstract/5/2/137/2317/Ant-Algorithms-for-Discrete-Optimization). Artificial Life, 5(2), pp.137-172.
* Di Caro, G. and Dorigo, M., 1998. AntNet: Distributed stigmergetic control for communications networks. Journal of Artificial Intelligence Research, 9, pp.317-365.
* Dorigo, M. and Gambardella, L.M., 1997. Ant colony system: A cooperative learning approach to the traveling salesman problem. IEEE Transactions on Evolutionary Computation, 1(1), pp.53-66.
* Dorigo, M., Maniezzo, V. and Colorni, A., 1996. Ant system: Optimization by a colony of cooperating agents. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 26(1), pp.29-41.
* [Gambardella, L.M.](https://people.idsia.ch/~luca/) and [Dorigo, M.](https://iridia.ulb.ac.be/~mdorigo/HomePageDorigo/), 1995. Ant-Q: A reinforcement learning approach to the traveling salesman problem. In International Conference on Machine Learning (pp. 252-260). Morgan Kaufmann.
* [Biosystems, 1997](https://www.sciencedirect.com/science/article/pii/S0303264797017085), [TEVC - Guest Editorial, 2002](https://ieeexplore.ieee.org/document/1027743), [Book Review on Artificial Intelligence (2005)](https://www.sciencedirect.com/science/article/pii/S0004370205000494), [Economist, 2010](https://www.antoptima.com/pdf/pdfrassegna/Economist.pdf), etc.

## Particle Swarm Optimization (PSO)

**CBO**: [Bungert et al., 2024, MP](https://link.springer.com/article/10.1007/s10107-024-02095-y); [Huang et al., 2024, SICON](https://epubs.siam.org/doi/abs/10.1137/22M1543367); [Schillings et al., 2023, SIAM/ASA-JUQ](https://epubs.siam.org/doi/abs/10.1137/22M1533281); [Fornasie et al., 2021](https://arxiv.org/abs/2103.15130); [Carrillo et al., ESAIM, 2021](https://www.esaim-cocv.org/articles/cocv/abs/2021/01/cocv190163/cocv190163.html); [Ha et al., 2020](https://www.worldscientific.com/doi/abs/10.1142/S0218202520500463)

* Carrillo, J.A., Choi, Y.P., Totzeck, C. and Tse, O., 2018. An analytical framework for consensus-based global optimization method. Mathematical Models and Methods in Applied Sciences, 28(06), pp.1037-1066.
* Pinnau, R., Totzeck, C., Tse, O. and Martin, S., 2017. A consensus-based model for global optimization and its mean-field limit. Mathematical Models and Methods in Applied Sciences, 27(01), pp.183-204.
* Eberhart, R.C., Shi, Y. and Kennedy, J., 2001. [Swarm intelligence](https://www.sciencedirect.com/book/9781558605954/swarm-intelligence). Elsevier.
* Kennedy, J. and Eberhart, R., 1995, November. Particle swarm optimization. In Proceedings of International Conference on Neural Networks (Vol. 4, pp. 1942-1948). IEEE.

## Non-dominated Sorting Genetic Algorithm II (NSGA-II)

* [Deb, K.](https://www.egr.msu.edu/~kdeb/), Pratap, A., Agarwal, S. and Meyarivan, T.A.M.T., 2002. [A fast and elitist multiobjective genetic algorithm: NSGA-II](https://ieeexplore.ieee.org/document/996017). IEEE Transactions on Evolutionary Computation, 6(2), pp.182-197. [ Kalyanmoy Deb: [ACM Fellow](https://dl.acm.org/doi/abs/10.1145/3594261.3594262) + IEEE Fellow + [IEEE CIS Evolutionary Computation Pioneer Award](https://msutoday.msu.edu/news/2018/kalyanmoy-deb-earns-prestigious-evolutionary-computation-award) ]
* Deb, K., 2001. Multi-objective optimization using evolutionary algorithms. John Wiley & Sons.

## Multi-Objective Evolutionary Algorithm based on Decomposition (MOEA/D)

* Zhang, Q. and Li, H., 2007. MOEA/D: A multiobjective evolutionary algorithm based on decomposition. IEEE Transactions on Evolutionary Computation, 11(6), pp.712-731.

## CoOperative coEvolutionary Algorithms (COEA)

* Gomez, F., Schmidhuber, J. and Miikkulainen, R., 2008. Accelerated neural evolution through cooperatively coevolved synapses. Journal of Machine Learning Research, 9(31), pp.937-965.
* Panait, L., Tuyls, K. and Luke, S., 2008. Theoretical advantages of lenient learners: An evolutionary game theoretic perspective. Journal of Machine Learning Research, 9, pp.423-457.
* Schmidhuber, J., Wierstra, D., Gagliolo, M. and Gomez, F., 2007. Training recurrent networks by evolino. Neural Computation, 19(3), pp.757-779.
* Gomez, F.J. and Schmidhuber, J., 2005, June. Co-evolving recurrent neurons learn deep memory POMDPs. In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 491-498). ACM.
* Fan, J., Lau, R. and Miikkulainen, R., 2003. Utilizing domain knowledge in neuroevolution. In International Conference on Machine Learning (pp. 170-177).
* Potter, M.A. and De Jong, K.A., 2000. Cooperative coevolution: An architecture for evolving coadapted subcomponents. Evolutionary Computation, 8(1), pp.1-29.
* Gomez, F.J. and Miikkulainen, R., 1999, July. Solving non-Markovian control tasks with neuroevolution. In Proceedings of International Joint Conference on Artificial Intelligence (pp. 1356-1361).
* Moriarty, D.E. and Mikkulainen, R., 1996. Efficient reinforcement learning through symbiotic evolution. Machine Learning, 22(1), pp.11-32.
* Moriarty, D.E. and Miikkulainen, R., 1995. Efficient learning from delayed rewards through symbiotic evolution. In International Conference on Machine Learning (pp. 396-404). Morgan Kaufmann.
* Potter, M.A. and De Jong, K.A., 1994, October. A cooperative coevolutionary approach to function optimization. In International Conference on Parallel Problem Solving from Nature (pp. 249-257). Springer, Berlin, Heidelberg.
* Hillis, W.D., 1990. Co-evolving parasites improve simulated evolution as an optimization procedure. Physica D: Nonlinear Phenomena, 42(1-3), pp.228-234.

## CoMpetitive co-Evolutionary Algorithms (CMEA)

* Ficici, S.G. and Pollack, J.B., 2000. A game-theoretic approach to the simple coevolutionary algorithm. In Parallel Problem Solving from Nature (pp. 467-476). Springer Berlin Heidelberg.
* Ficici, S.G. and Pollack, J.B., 1998, June. Challenges in coevolutionary learning: Arms-race dynamics, open-endedness, and mediocre stable states. In Proceedings of International Conference on Artificial Life (pp. 238-247). Cambridge, MA: MIT Press.
* Rosin, C.D. and Belew, R.K., 1997. New methods for competitive coevolution. Evolutionary Computation, 5(1), pp.1-29.

## Differential Evolution (DE)

* Price, K.V., 2013. [Differential evolution](https://link.springer.com/chapter/10.1007/978-3-642-30504-7_8). In Handbook of Optimization: From Classical to Modern Approach (pp. 187-214). Berlin, Heidelberg: Springer Berlin Heidelberg.
* Das, S. and Suganthan, P.N., 2010. [Differential evolution: A survey of the state-of-the-art](https://ieeexplore.ieee.org/abstract/document/5601760). IEEE Transactions on Evolutionary Computation, 15(1), pp.4-31.
* Storn, R., 1999. [System design by constraint adaptation and differential evolution](https://ieeexplore.ieee.org/abstract/document/752918). IEEE Transactions on Evolutionary Computation, 3(1), pp.22-34.
* Storn, R. and Price, K., 1997. [Differential evolution–A simple and efficient heuristic for global optimization over continuous spaces](https://link.springer.com/article/10.1023/a:1008202821328). Journal of Global Optimization, 11(4), pp.341-359.
* Storn, R., 1996, May. Differential evolution design of an IIR-filter. In Proceedings of IEEE International Conference on Evolutionary Computation (pp. 268-273). IEEE.

## Estimation of Distribution Algorithms (EDAs)

* Zhang, Q. and Muhlenbein, H., 2004. [On the convergence of a class of estimation of distribution algorithms](https://ieeexplore.ieee.org/abstract/document/1288052). IEEE Transactions on Evolutionary Computation, 8(2), pp.127-136.
* Larrañaga, P. and Lozano, J.A. eds., 2001. Estimation of distribution algorithms: A new tool for evolutionary computation. Springer Science & Business Media.
* Inza, I., Larrañaga, P., Etxeberria, R. and Sierra, B., 2000. Feature subset selection by Bayesian network-based optimization. Artificial Intelligence, 123(1-2), pp.157-184.
* Baluja, S., 1996. Genetic algorithms and explicit search statistics. In Advances in Neural Information Processing Systems, pp.319-325.
* Baluja, S. and Caruana, R., 1995. Removing the genetics from the standard genetic algorithm. In International Conference on Machine Learning (pp. 38-46). Morgan Kaufmann.

## Natural Evolution Strategies (NES)

* Hüttenrauch, M. and Neumann, G., 2024. [Robust black-box optimization for stochastic search and episodic reinforcement learning](https://www.jmlr.org/papers/v25/22-0564.html). Journal of Machine Learning Research, 25(153), pp.1-44.
* Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., Elibol, M., Yang, Z., Paul, W., Jordan, M.I. and Stoica, I., 2018. [Ray: A distributed framework for emerging AI applications](https://www.usenix.org/conference/osdi18/presentation/moritz). In USENIX Symposium on Operating Systems Design and Implementation (pp. 561-577).
* Salimans, T., Ho, J., Chen, X., Sidor, S. and Sutskever, I., 2017. [Evolution strategies as a scalable alternative to reinforcement learning](https://arxiv.org/abs/1703.03864). arXiv preprint arXiv:1703.03864.
* Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J. and Schmidhuber, J., 2014. [Natural evolution strategies](https://jmlr.org/papers/v15/wierstra14a.html). Journal of Machine Learning Research, 15(1), pp.949-980.
* Yi, S., Wierstra, D., Schaul, T. and Schmidhuber, J., 2009, June. [Stochastic search using the natural gradient](https://dl.acm.org/doi/10.1145/1553374.1553522). In International Conference on Machine Learning (pp. 1161-1168).

## Quality Diversity (QD)

* https://quality-diversity.github.io/    (Now it is actively updated by Antoine Cully, Jean-Baptiste Mouret, and Stephane Doncieux.)
* Fontaine, M.C. and Nikolaidis, S., 2021. Differentiable quality diversity. Advances in Neural Information Processing Systems.
* Ecoffet, A., Huizinga, J., Lehman, J., Stanley, K.O. and Clune, J., 2021. [First return, then explore](https://www.nature.com/articles/s41586-020-03157-9). Nature, 590(7847), pp.580-586.
* Chatzilygeroudis, K., Cully, A., Vassiliades, V. and Mouret, J.B., 2021. Quality-diversity optimization: A novel branch of stochastic optimization. In Black Box Optimization, Machine Learning, and No-Free Lunch Theorems (pp. 109-135). Springer, Cham.
* Cully, A. and Demiris, Y., 2018. Quality and diversity optimization: A unifying modular framework. IEEE Transactions on Evolutionary Computation, 22(2), pp.245-259.
* Pugh, J.K., Soros, L.B. and Stanley, K.O., 2016. Quality diversity: A new frontier for evolutionary computation. Frontiers in Robotics and AI, 3, pp.1-17.
* Cully, A., Clune, J., Tarapore, D. and Mouret, J.B., 2015. [Robots that can adapt like animals](https://www.nature.com/articles/nature14422). Nature, 521(7553), pp.503-507.
* Mouret, J.B. and Clune, J., 2015. Illuminating search spaces by mapping elites. arXiv preprint arXiv:1504.04909.
* Lehman, J. and Stanley, K.O., 2011, July. [Evolving a diversity of virtual creatures through novelty search and local competition](https://dl.acm.org/doi/abs/10.1145/2001576.2001606). In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 211-218).
* Lehman, J. and Stanley, K.O., 2011. [Abandoning objectives: Evolution through the search for novelty alone](https://ieeexplore.ieee.org/abstract/document/6793380). Evolutionary Computation, 19(2), pp.189-223.

## NeuroEvolution (aka Evolving Neural Networks) [ [wired](https://www.wired.com/story/the-pursuit-of-creativity-can-make-algorithms-much-smarter/) ]

* Stanley, K.O., Clune, J., Lehman, J. and Miikkulainen, R., 2019. Designing neural networks through neuroevolution. Nature Machine Intelligence, 1(1), pp.24-35.
* Jaderberg, M., Czarnecki, W.M., Dunning, I., Marris, L., Lever, G., Castaneda, A.G., Beattie, C., Rabinowitz, N.C., Morcos, A.S., Ruderman, A. and Sonnerat, N., 2019. Human-level performance in 3D multiplayer games with population-based reinforcement learning. Science, 364(6443), pp.859-865.
* Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., Elibol, M., Yang, Z., Paul, W., Jordan, M.I. and Stoica, I., 2018. Ray: A distributed framework for emerging AI applications. In USENIX Symposium on Operating Systems Design and Implementation (pp. 561-577).
* Floreano, D., Dürr, P. and Mattiussi, C., 2008. Neuroevolution: From architectures to learning. Evolutionary Intelligence, 1(1), pp.47-62.
* Stanley, K.O. and Miikkulainen, R., 2002. Evolving neural networks through augmenting topologies. Evolutionary Computation, 10(2), pp.99-127.
* Yao, X., 1999. Evolving artificial neural networks. Proceedings of the IEEE, 87(9), pp.1423-1447.

## Evolutionary/Swarm Robotics

* Floreano, D. and Lipson, H., 2021. [From individual robots to robot societies](https://www.science.org/doi/full/10.1126/scirobotics.abk2787). Science Robotics, 6(56).
* Dorigo, M., Theraulaz, G. and Trianni, V., 2021. Swarm robotics: Past, present, and future. Proceedings of the IEEE, 109(7), pp.1152-1165.
* Kriegman, S., Blackiston, D., Levin, M. and Bongard, J., 2020. A scalable pipeline for designing reconfigurable organisms. Proceedings of the National Academy of Sciences, 117(4), pp.1853-1859.
* Dorigo, M., Theraulaz, G. and Trianni, V., 2020. Reflections on the future of swarm robotics. Science Robotics, 5(49).
* Howard, D., Eiben, A.E., Kennedy, D.F., Mouret, J.B., Valencia, P. and Winkler, D., 2019. Evolving embodied intelligence from materials to machines. Nature Machine Intelligence, 1(1), pp.12-19.
* Doncieux, S., Bredeche, N., Mouret, J.B. and Eiben, A.E.G., 2015. Evolutionary robotics: What, why, and where to. Frontiers in Robotics and AI, 2, p.4.
* Bongard, J. and Lipson, H., 2014. Evolved machines shed light on robustness and resilience. Proceedings of the IEEE, 102(5), pp.899-914.
* Bongard, J.C., 2013. Evolutionary robotics. Communications of the ACM, 56(8), pp.74-83.
* Pfeifer, R. and Bongard, J., 2007. How the body shapes the way we think: A new view of intelligence. MIT Press.
* Nolfi, S. and Floreano, D., 2000. Evolutionary robotics: The biology, intelligence, and technology of self-organizing machines. MIT Press.
* Lipson, H. and Pollack, J.B., 2000. Automatic design and manufacture of robotic lifeforms. Nature, 406(6799), pp.974-978.
* Jakobi, N., 1997. [Evolutionary robotics and the radical envelope-of-noise hypothesis](https://journals.sagepub.com/doi/abs/10.1177/105971239700600205). Adaptive Behavior, 6(2), pp.325-368.
* Sims, K., 1995. Evolving 3D morphology and behavior by competition. Artificial Life, 1(4), pp.353-372.
* Sims, K., 1994, July. Evolving virtual creatures. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques (pp. 15-22).
* Reynolds, C.W., 1987, August. Flocks, herds and schools: A distributed behavioral model. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques (pp. 25-34).

## Evolutionary Design
* Bentley, P., 1999. [Evolutionary design by computers](https://www.amazon.com/Evolutionary-Design-Computers-Peter-Bentley/dp/155860605X). Morgan Kaufmann.

## Algorithm Selection and Configuration (and Meta-EAs)
* [Eiben, A.E.](https://www.cs.vu.nl/~gusz/) and Smit, S.K., 2012. [Evolutionary algorithm parameters and methods to tune them](). Autonomous Search, pp.15-36.
* Grefenstette, J.J., 1986. [Optimization of control parameters for genetic algorithms](https://ieeexplore.ieee.org/abstract/document/4075583). IEEE Transactions on Systems, Man, and Cybernetics, 16(1), pp.122-128.

## Broader Viewpoints From CS/AI/ML/Optimization/OR/Biology

* Zador, A., Escola, S., Richards, B., Ölveczky, B., Bengio, Y., Boahen, K., Botvinick, M., Chklovskii, D., Churchland, A., Clopath, C. and DiCarlo, J., 2023. [Catalyzing next-generation Artificial Intelligence through NeuroAI](https://www.nature.com/articles/s41467-023-37180-x). Nature Communications, 14(1), p.1597.
  * "Put another way, we can greatly accelerate our search for general-purpose circuits for realworld interaction by taking advantage of the optimization process that evolution has already engaged in."
    * Stanley, K. O., Clune, J., Lehman, J. & Miikkulainen, R. Designing neural networks through neuroevolution. Nat. Mach. Intell. 1, 24–35 (2019).
    * Gupta, A., Savarese, S., Ganguli, S. & Fei-Fei, L. Embodied intelligence via learning and evolution. Nat. Commun. 12, 5721 (2021).
* Turner, R., Eriksson, D., McCourt, M., Kiili, J., Laaksonen, E., Xu, Z. and Guyon, I., 2021, August. [Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020](http://proceedings.mlr.press/v133/turner21a/turner21a.pdf). In NeurIPS 2020 Competition and Demonstration Track (pp. 3-26). PMLR. [ https://bbochallenge.com/ ]
* Millhouse, T., Moses, M. and Mitchell, M., 2021. Foundations of intelligence in natural and artificial systems: A workshop report. arXiv preprint arXiv:2105.02198.
* Lehman, J., Clune, J., Misevic, D., Adami, C., Altenberg, L., Beaulieu, J., Bentley, P.J., Bernard, S., Beslon, G., Bryson, D.M. and Cheney, N., 2020. [The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities](https://direct.mit.edu/artl/article/26/2/274/93255/The-Surprising-Creativity-of-Digital-Evolution-A). Artificial Life, 26(2), pp.274-306.
* [https://www.quantamagazine.org/computers-evolve-a-new-path-toward-human-intelligence-20191106/](https://www.quantamagazine.org/computers-evolve-a-new-path-toward-human-intelligence-20191106/)
* Clune, J., 2019. AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence. arXiv preprint arXiv:1905.10985.
* Kerschke, P., Hoos, H.H., Neumann, F. and Trautmann, H., 2019. Automated algorithm selection: Survey and perspectives. Evolutionary Computation, 27(1), pp.3-45.
* Forrest, S. and Mitchell, M., 2016. Adaptive computation: The multidisciplinary legacy of John H. Holland. Communications of the ACM, 59(8), pp.58-63.
* Livnat, A. and Papadimitriou, C., 2016. [Sex as an algorithm: The theory of evolution under the lens of computation](https://cacm.acm.org/research/sex-as-an-algorithm/). Communications of the ACM, 59(11), pp.84-93.
* Domingos, P., 2015. The master algorithm: How the quest for the ultimate learning machine will remake our world. Basic Books.
  * Domingos, P., 2015. [The five tribes of machine learning and what you can take from each](https://learning.acm.org/techtalks/machinelearning). ACM Learning Center. [ [pdf](https://learning.acm.org/binaries/content/assets/leaning-center/webinar-slides/2015/five-tribes-ml_112415.pdf) ]
* Stulp, F. and Sigaud, O., 2012, June. [Path integral policy improvement with covariance matrix adaptation](https://icml.cc/2012/papers/171.pdf). In International Coference on International Conference on Machine Learning (pp. 1547-1554).
* Floreano, D. and Mattiussi, C., 2008. Bio-inspired artificial intelligence: Theories, methods, and technologies. MIT Press.
* Spall, J.C., Hill, S.D. and Stark, D.R., 2006. [Theoretical framework for comparing several stochastic optimization approaches](https://link.springer.com/chapter/10.1007/1-84628-095-8_3). Probabilistic and Randomized Methods for Design Under Uncertainty, pp.99-117.
* Fogel, D.B., Anderson, R.W., Reynolds, R.G. and Rizki, M.M., 2001. [Memorial tribute to Dr. Michael Conrad](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=910460). IEEE Transactions on Evolutionary Computation, 5(1), pp.1-2.
  * Conrad, M. and Pattee, H.H., 1970. [Evolution experiments with an artificial ecosystem](https://www.sciencedirect.com/science/article/abs/pii/0022519370900779). Journal of Theoretical Biology, 28(3), pp.393-409.
* Levine, D., 1997. [Commentary—Genetic algorithms: A practitioner's view](https://pubsonline.informs.org/doi/10.1287/ijoc.9.3.256). INFORMS Journal on Computing, 9(3), pp.256-259.
* Conrad, M. and Rizki, M.M., 1989. [The artificial worlds approach to emergent evolution](https://www.sciencedirect.com/science/article/abs/pii/0303264789900324). BioSystems, 23(2-3), pp.247-258.
* Axelrod, R., 1987. The evolution of strategies in the iterated prisoner’s dilemma. Genetic Algorithms and Simulated Annealing.
* Fogel, D.B., 2006. [Nils Barricelli-artificial life, coevolution, self-adaptation](https://ieeexplore.ieee.org/abstract/document/1597062). IEEE Computational Intelligence Magazine, 1(1), pp.41-45.
* Atmar III, J.W., 1976. Speculation on the evolution of intelligence and its possible realization in machine form. New Mexico State University.
* Newell, A. and Simon, H.A., 1975. [Computer science as empirical inquiry: Symbols and search](https://dl.acm.org/doi/pdf/10.1145/1283920.1283930). In ACM Turing Award Lectures (p. 1975).
* Reed, J., Toombs, R. and Barricelli, N.A., 1967. [Simulation of biological evolution and machine learning: I. Selection of self-reproducing numeric patterns by data processing machines, effects of hereditary control, mutation type and crossing](). Journal of Theoretical Biology, 17(3), pp.319-342.
* Bremermann, H.J., 1962. [Optimization through evolution and recombination](https://github.com/Evolutionary-Intelligence/DistributedEvolutionaryComputation/blob/main/Pub/History-Papers/%5B1962%5D%20Optimization%20through%20evolution%20and%20recombination.pdf). Self-Organizing Systems, 93, p.106.
  * Bremermann, H.J., 1968. Numerical optimization procedures derived from biological evolution processes. Cybernetic Problems in Bionics, pp.597-616.
  * https://newsarchive.berkeley.edu/news/media/releases/96legacy/releases.96/14319.html [ [pdf](https://github.com/Evolutionary-Intelligence/DistributedEvolutionaryComputation/blob/main/Pub/History-Papers/%5B1996%5D%20UC%20Berkeley's%20Hans%20Bremermann%2C%20professor%20emeritus%20and%20pioneer%20in%20mathematical%20biology%2C%20has%20died%20at%2069.pdf) ]
* [Turing, A.M.](https://en.wikipedia.org/wiki/Alan_Turing), 1948. [Intelligent machinery](https://weightagnostic.github.io/papers/turing1948.pdf). In The Essential Turing. Oxford University Press.
  * Copeland, B.J. ed., 2004. [The essential Turing: Seminal writings in computing, logic, philosophy, artificial intelligence, and artificial life plus the secrets of enigma](https://global.oup.com/academic/product/the-essential-turing-9780198250807). Oxford University Press.
  * Turing, A.M., 2009. [Computing machinery and intelligence (pp. 23-65)](https://link.springer.com/chapter/10.1007/978-1-4020-6710-5_3). Springer Netherlands.
  * [https://academic.oup.com/mind/article/LIX/236/433/986238](https://academic.oup.com/mind/article/LIX/236/433/986238)

# Some Interesting Applications

 * [AirBus](https://www.airbus.com/en/newsroom/news/2016-03-pioneering-bionic-3d-printing)
   * [AutoDesk](https://www.autodesk.com/research/projects/bionic-partition-project) [ [paper](https://damassets.autodesk.net/content/dam/autodesk/research/publications-assets/pdf/naturebased-hybrid-computational-geometry.pdf) ]
* [Bank of Canada](https://www.econstor.eu/bitstream/10419/241168/1/swp2020-02.pdf): **CMA-ES**
* [Beijing National Stadium (Bird's Nest) & Beijing National Aquatics Centre (Water Cube)](https://www.cadalyst.com/cad/building-design/generative-design-is-changing-face-architecture-12948)
* [BMW Group](https://dl.acm.org/doi/abs/10.1145/3512290.3528712)
* Google
  * [Multitask Learning](https://arxiv.org/pdf/2205.12755.pdf) | [Multitask Systems](https://arxiv.org/pdf/2205.10937.pdf)
  * [Symbolic Functional Evolutionary Search (SyFES)](https://www.science.org/doi/full/10.1126/sciadv.abq0279)
* [Honda](https://www.tandfonline.com/doi/abs/10.1080/13588265.2017.1331493)
* IBM
  * [JPMorgan Chase & Co.](https://arxiv.org/abs/1910.09694)
* [OpenAI](https://openai.com/research/evolution-strategies) | [open-source code](https://github.com/openai/evolution-strategies-starter)
* [Siemens Healthcare XP Division](https://iopscience.iop.org/article/10.1088/0031-9155/61/8/3009)

# MetaHeuristics

* https://ryojitanabe.github.io/ecconf/: Statistics of acceptance rates of some EC conferences.
* Campelo, F. and Aranha, C., 2023. [Lessons from the evolutionary computation Bestiary](https://publications.aston.ac.uk/id/eprint/44574/1/ALIFE_LLCS.pdf). Artificial Life, 29(4), pp.421-432.
  * "While metaphors can be powerful inspiration tools, the emergence of hundreds of barely discernible algorithmic variants under different labels and nomenclatures has been counterproductive to the scientific progress of the field, as it neither improves our ability to understand and simulate biological systems, nor contributes generalisable knowledge or design principles for global optimisation approaches."
* [Bäck, T.H.](https://www.universiteitleiden.nl/en/staffmembers/thomas-back), Kononova, A.V., van Stein, B., Wang, H., Antonov, K.A., Kalkreuth, R.T., de Nobel, J., Vermetten, D., de Winter, R. and Ye, F., 2023. [Evolutionary algorithms for parameter optimization—Thirty years later](https://direct.mit.edu/evco/article/31/2/81/115462). Evolutionary Computation, 31(2), pp.81-122.
  * Bäck, T., Doerr, C., Sendhoff, B. and Stützle, T., 2022. [Guest editorial special issue on benchmarking sampling-based optimization heuristics: Methodology and software](https://ieeexplore.ieee.org/abstract/document/9967395). IEEE Transactions on Evolutionary Computation, 26(6), pp.1202-1205.
* Hansen, N., Auger, A., Brockhoff, D. and Tušar, T., 2022. [Anytime performance assessment in blackbox optimization benchmarking](https://ieeexplore.ieee.org/abstract/document/9905722). IEEE Transactions on Evolutionary Computation, 26(6), pp.1293-1305.
  * Auger, A., Hansen, N. and Schoenauer, M., 2012. [Benchmarking of continuous black box optimization algorithms](https://direct.mit.edu/evco/article-abstract/20/4/481/956/Benchmarking-of-Continuous-Black-Box-Optimization). Evolutionary Computation, 20(4), pp.481-481. [ [bbob-largescale](https://www.sciencedirect.com/science/article/pii/S156849462030675X) ]
* Kudela, J., 2022. [A critical problem in benchmarking and analysis of evolutionary computation methods](https://www.nature.com/articles/s42256-022-00579-0). Nature Machine Intelligence, 4(12), pp.1238-1245.
* Swan, J., Adriaensen, S., Brownlee, A.E., Hammond, K., Johnson, C.G., Kheiri, A., Krawiec, F., Merelo, J.J., Minku, L.L., Özcan, E., Pappa, G.L., et al., 2022. [Metaheuristics “in the large”](https://www.sciencedirect.com/science/article/pii/S0377221721004707). European Journal of Operational Research, 297(2), pp.393-406.
  * Aranha, C., Camacho Villalón, C.L., Campelo, F., Dorigo, M., Ruiz, R., Sevaux, M., Sörensen, K. and Stützle, T., 2022. [Metaphor-based metaheuristics, a call for action: The elephant in the room](https://link.springer.com/article/10.1007/s11721-021-00202-9). Swarm Intelligence, 16(1), pp.1-6.
* de Armas, J., Lalla-Ruiz, E., Tilahun, S.L. and Voß, S., 2022. [Similarity in metaheuristics: A gentle step towards a comparison methodology](https://link.springer.com/article/10.1007/s11047-020-09837-9). Natural Computing, 21(2), pp.265-287.
* Sörensen, K., Sevaux, M. and Glover, F., 2018. [A history of metaheuristics](https://link.springer.com/referenceworkentry/10.1007/978-3-319-07124-4_4). In Handbook of Heuristics (pp. 791-808). Springer, Cham.
  * Sörensen, K., 2015. [Metaheuristics—the metaphor exposed](https://onlinelibrary.wiley.com/doi/full/10.1111/itor.12001). International Transactions in Operational Research, 22(1), pp.3-18.
* For more discussions of metaphor-based metaheuristics, see e.g., [Villalón et al., 2022, ITOR](https://onlinelibrary.wiley.com/doi/abs/10.1111/itor.13176); [Villalón et al., 2022](https://www.sciencedirect.com/science/article/pii/S0305054822000442); [Villalón et al., 2021](https://iridia.ulb.ac.be/IridiaTrSeries/rev/IridiaTr2021-006r001.pdf); [Villalón et al., 2020, ANTS](https://link.springer.com/chapter/10.1007/978-3-030-60376-2_10); [Sörensen et al., 2019, ITOR](https://onlinelibrary.wiley.com/doi/full/10.1111/itor.12443); [Weyland, 2015](https://www.sciencedirect.com/science/article/pii/S221471601500010X); [Weyland, 2010](https://www.igi-global.com/article/rigorous-analysis-harmony-search-algorithm/44954).
