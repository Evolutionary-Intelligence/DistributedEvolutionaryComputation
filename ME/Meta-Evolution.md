# Meta-Evolution

* Coward, S., Lu, C., Letcher, A., Jiang, M., Parker-Holder, J. and Foerster, J.N., [Higher order and self-referential evolution for population-based methods](https://openreview.net/pdf?id=3tk6AES1Aj). In Automated Reinforcement Learning: Exploring Meta-Learning, AutoML, and LLMs.
* Lu, C., Towers, S. and Foerster, J., 2023, July. [Arbitrary order meta-learning with simple population-based evolution](https://direct.mit.edu/isal/proceedings-pdf/isal2023/35/67/2354943/isal_a_00674.pdf). In Proceedings of Artificial Life Conference. MIT Press.
* Lange, R., Schaul, T., Chen, Y., Zahavy, T., Dalibard, V., Lu, C., Singh, S. and Flennerhag, S., 2023, July. Discovering evolution strategies via meta-black-box optimization. In Proceedings of the Companion Conference on Genetic and Evolutionary Computation (pp. 29-30).
* Miconi, T., 2023, July. Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning. In International Conference on Machine Learning (pp. 24756-24774). PMLR.
* Lu, C., Kuba, J., Letcher, A., Metz, L., Schroeder de Witt, C. and Foerster, J., 2022. Discovered policy optimisation. Advances in Neural Information Processing Systems, 35, pp.16455-16468.
* Kumar, A., Liu, B., Miikkulainen, R. and Stone, P., 2022, July. Effective mutation rate adaptation through group elite selection. In Proceedings of Genetic and Evolutionary Computation Conference (pp. 721-729). ACM.
* Parker-Holder, J., Jiang, M., Dennis, M., Samvelyan, M., Foerster, J., Grefenstette, E. and Rocktäschel, T., 2022, June. Evolving curricula with regret-based environment design. In International Conference on Machine Learning (pp. 17473-17498). PMLR.
* Wang, J.X., 2021. Meta-learning in natural and artificial intelligence. Current Opinion in Behavioral Sciences, 38, pp.90-95.
  * "The fundamental principle of meta-learning is that learning proceeds faster with more experience, via the acquisition of inductive biases or knowledge that allows for more efficient learning in the future."
  * "Meta-learning is prevalent in nature, being naturally multi-scaled. ... There exists a range of learning mechanisms that span these different timescales."
  * "Within cognitive science, hierarchical Bayesian models of cognition capture how learning can occur at multiple scales and via the acquisition of useful, structured priors."
  * "Meta-learning as learning of meta-parameters: Also called ‘hyper-’ or ‘meta-parameters’"
  * "Meta-learning over representations: Such a hierarchically structured organization is intriguingly suggestive of the multi-scaled nature of meta-learning systems"
  * "Meta-learning as latent state and Bayesian inference"
* Hellwig, M. and Beyer, H.G., 2019, July. Analysis of a meta-ES on a conically constrained problem. In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 673-681). ACM.
  * Theoretical paper: Dynamics of mutation strength control
  * Algorithm(s): Meta-ES
  * Problem(s): Conically constrained problem
* Fernando, C., Sygnowski, J., Osindero, S., Wang, J., Schaul, T., Teplyashin, D., Sprechmann, P., Pritzel, A. and Rusu, A., 2018, July. Meta-learning by the baldwin effect. In Proceedings of the Genetic and Evolutionary Computation Conference Companion (pp. 1313-1320).
* Metz, L., Freeman, C.D., Maheswaranathan, N. and Sohl-Dickstein, J., 2021. Training learned optimizers with randomly initialized learned optimizers. arXiv preprint arXiv:2101.07367.
* Stanley, K.O., Lehman, J. and Soros, L., 2017. [Open-endedness: The last grand challenge you’ve never heard of. While open-endedness could be a force for discovering intelligence, it could also be a component of AI itself](https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/).
  * "Almost no one has even heard of this problem, let alone cares about its solution, even though it is among the most fascinating and profound challenges that might actually someday be solved."
  * "Evolution is also the never-ending algorithm, a process that tirelessly invents ever-greater complexity and novelty across incomprehensible spans of time. In fact, there’s another term that captures this notion of a single process that invents astronomical complexity for near-eternity—we call it “open-ended.”"
* Sean Luke, AKM Khaled Ahsan Talukder, 2013, July. [Is the meta-EA a viable optimization method?](https://dl.acm.org/doi/10.1145/2463372.2465806). In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 1533-1540). ACM.
  * Experimental paper: Meta-EAs
  * Algorithms(s): ES (meta-level) + EAs (GA | ES | DE)
  * Problem(s):
  * Computing platform: On a supercomputer cluster (128 processors)
* Harrington, K.I., Spector, L., Pollack, J.B. and O'Reilly, U.M., 2012, July. Autoconstructive evolution for structural problems. In Proceedings of Annual Conference companion on Genetic and evolutionary computation (pp. 75-82).
* Branke, J. and Elomari, J.A., 2012, July. Meta-optimization for parameter tuning with a flexible computing budget. In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 1245-1252).
* Lynch, M., 2010. [Evolution of the mutation rate](https://www.sciencedirect.com/science/article/pii/S0168952510001034). Trends in Genetics, 26(8), pp.345-352. [ Indiana University ]
* Adenso-Diaz, B. and Laguna, M., 2006. Fine-tuning of algorithms using fractional experimental designs and local search. Operations Research, 54(1), pp.99-114.
* Clune, J., Goings, S., Punch, B. and Goodman, E., 2005, June. Investigations in meta-GAs: Panaceas or pipe dreams?. In Proceedings of Annual Workshop on Genetic and Evolutionary Computation (pp. 235-241).
  * Experimental paper: Meta-GAs
  * Algorithms(s): Meta-GAs (subpopulations)
  * Problem(s): on two toy problems ('counting ones' and '4-bit deceptive trap')
  * Computing platform:
  * "Original promise of solving challenging problems with minimal human involvement" + "‘generalists’ and ‘specialists’"
* Belle, T.V. and Ackley, D.H., 2002, July. Code factoring and the evolution of evolvability. In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 1383-1390). ACM.
* Gould, S.J., 2002. [The structure of evolutionary theory](https://www.hup.harvard.edu/books/9780674006133).
  * "Hierarchical Selection: Interdemic (or so-called group) selection"
  * "Species selection—though clearly valid in logic and therefore subject to realization in nature—must be far too weak (relative to organismic selection) to have any practical effect upon evolution."
  * "When we factor punctuated equilibria into the equation, species selection emerges as a powerful force in macroevolution (though not as an architect of complex organismic adaptations)."
  * "Organismic selection must overwhelm species selection when both processes operate steadily and towards the same adaptive "goal"—for if both levels work in the same direction, then species selection can only add the merest increment to the vastly greater power of organismic selection; whereas, if the two levels work in opposite directions, organismic selection must overwhelm and cancel the effect of species selection."
* Hansen, N. and Ostermeier, A., 2001. Completely derandomized self-adaptation in evolution strategies. Evolutionary Computation, 9(2), pp.159-195.
* Rudolph, G., 2001. Self-adaptive mutations may lead to premature convergence. IEEE Transactions on Evolutionary Computation, 5(4), pp.410-414.
* Eiben, Á.E., Hinterding, R. and Michalewicz, Z., 1999. Parameter control in evolutionary algorithms. IEEE Transactions on evolutionary computation, 3(2), pp.124-141.
* Kirschner, M. and Gerhart, J., 1998. [Evolvability](https://www.pnas.org/doi/abs/10.1073/pnas.95.15.8420). Proceedings of the National Academy of Sciences, 95(15), pp.8420-8427. [ Harvard Medical School +  University of California, Berkeley ]
  * "Evolvability is an organism’s capacity to generate heritable phenotypic variation. ...The capacity of a lineage to evolve has been termed its evolvability, also called evolutionary adaptability."
  * "Confer evolvability on the organism by reducing constraints on change and allowing the accumulation of nonlethal variation"
* [Wagner, G.P.](https://campuspress.yale.edu/wagner/) and Altenberg, L., 1996. [Perspective: Complex adaptations and the evolution of evolvability](https://academic.oup.com/evolut/article/50/3/967/6870900). Evolution, 50(3), pp.967-976. [ Yale University + University of Hawaii ]
* Altenberg, L., 1994. The evolution of evolvability in genetic programming. Advances in Genetic Programming, 3, pp.47-74.
* Schlierkamp-Voosen, D. and Mühlenbein, H., 1994. Strategy adaptation by competing subpopulations. In Parallel Problem Solving from Nature—PPSN III: International Conference on Evolutionary Computation The Third Conference on Parallel Problem Solving from Nature Jerusalem, Israel, October 9–14, 1994 Proceedings 3 (pp. 199-208). Springer Berlin Heidelberg.
* Srinivas, M. and Patnaik, L.M., 1994. Adaptive probabilities of crossover and mutation in genetic algorithms. IEEE Transactions on Systems, Man, and Cybernetics, 24(4), pp.656-667.
* Bäck, T., 1994, October. Parallel optimization of evolutionary algorithms. In International Conference on Parallel Problem Solving from Nature (pp. 418-427). Berlin, Heidelberg: Springer Berlin Heidelberg.
* Bäck, T., 1992, April. Self-adaptation in genetic algorithms. In Proceedings of First European Conference on Artificial Life (pp. 263-271). Cambridge: MIT press.
* Fogel, D.B., Fogel, L.J. and Atmar, J.W., 1991, January. Meta-evolutionary programming. In Conference record of the twenty-fifth asilomar conference on signals, systems & computers (pp. 540-541). IEEE computer Society.
* Dawkins, R., 1989. [The evolution of evolvability](https://www.taylorfrancis.com/chapters/edit/10.4324/9780429032769-10/evolution-evolvability-richard-dawkins). In Artificial Life (pp. 201-220). Routledge. [ University of Oxford ]
  * "To make a preliminary distinction between two kinds of mutation: ordinary changes within an existing genetic system, and changes to the genetic system itself"
  * "These changes to genetic systems must have been, at least in one sense, major changes, changes of a different order from the normal allele substitutions that go on within a genetic system."
  * "Although changes in genetic systems are much rarer than allelic substitutions within genetic systems, they are not very rare events on the geological timescale."
  * "A kind of higher-level selection, a selection not for survivability but for evolvability: It is only cumulative selection that is evolutionarily interesting, for only cumulative selection has the power to build new progress on the shoulders of earlier generations of progress, and hence the power to build up the formidable complexity that is diagnostic of life. Obviously the idea of each new adaptation serving as the background for the evolution of subsequent adaptations is commonplace, and is the essence of the idea of cumulative selection."
  * Dawkins, R., 1996. The blind watchmaker: Why the evidence of evolution reveals a universe without design. WW Norton & Company.
* [Schmidhuber, J.](https://people.idsia.ch/~juergen/), 1987. [Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook](https://people.idsia.ch/~juergen/diploma.html). Diploma Thesis, Technische Universität München (TUM).
  * "A system with such meta-learning capabilities should view every problem as consisting out of at least two problems: Solving it, and improving the strategies employed to solve it."
  * "This requires an initial representation of the system that allows it to introspect and manipulate all of its relevant parts."
  * "The essential ingredients of self-reflexivity and full introspection still have to be discovered."
* Grefenstette, J.J., 1986. Optimization of control parameters for genetic algorithms. IEEE Transactions on Systems, Man, and Cybernetics, 16(1), pp.122-128.
* Kant, E., 1985. Understanding and automating algorithm design. IEEE Transactions on Software Engineering, (11), pp.1361-1374.
* Mercer, R.E. and Sampson, J.R., 1978. Adaptive search using a reproductive meta‐plan. Kybernetes, 7(3), pp.215-228.
* CAVICCHIO, D., 1970. Adaptive search using simulated evolution. Doctoral Dissertation, University of Michigan.

![visitors](https://visitor-badge.laobi.icu/badge?page_id=Evolutionary-Intelligence.DistributedEvolutionaryComputation)
